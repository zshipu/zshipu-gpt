<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>技术分享 - 基于大模型（LLM）的智能化自助分析系统搭建探索 -- 知识铺 | GPT资讯  --  知识铺</title>
    <meta property="og:title" content="技术分享 - 基于大模型（LLM）的智能化自助分析系统搭建探索 -- 知识铺 - GPT资讯  --  知识铺">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2024-03-18T10:37:08&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2024-03-18T10:37:08&#43;08:00'>
        
    <meta name="Keywords" content="aigc,chatgpt,langchain,golang,go语言,go语言笔记,知识铺,java,android,博客,项目管理,python,React、Next、Vue、软件架构,公众号,小程序">
    <meta name="description" content="技术分享 - 基于大模型（LLM）的智能化自助分析系统搭建探索 -- 知识铺">
        <meta name="author" content="知识铺">
        
    <meta property="og:url" content="https://gpt.zshipu.com/post/202403/LLM/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8BLLM%E7%9A%84%E6%99%BA%E8%83%BD%E5%8C%96%E8%87%AA%E5%8A%A9%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA%E6%8E%A2%E7%B4%A2-%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1/">
    <link rel="shortcut icon" href='/favicon.ico'  type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    <script data-ad-client="ca-pub-2874221941555456" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    
    
    
    
    
    
    
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-WLWJSST');</script>
    
</head>


<body>

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WLWJSST"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://gpt.zshipu.com/">
                        GPT资讯  --  知识铺
                    </a>
                
                <p class="description">专注于AIGC、Android、Java、Go语言(golang)、React、Next、Vue、移动互联网、项目管理、软件架构</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://gpt.zshipu.com/">首页</a>
                    
                    <a  href="https://gpt.zshipu.com/archives/" title="归档">归档</a>
                    
                    <a  href="https://gpt.zshipu.com/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    <style type="text/css">
    .post-toc {
        position: fixed;
        width: 200px;
        margin-left: -210px;
        padding: 5px 10px;
        font-family: Athelas, STHeiti, Microsoft Yahei, serif;
        font-size: 12px;
        border: 1px solid rgba(0, 0, 0, .07);
        border-radius: 5px;
        background-color: rgba(255, 255, 255, 0.98);
        background-clip: padding-box;
        -webkit-box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        word-wrap: break-word;
        white-space: nowrap;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        z-index: 999;
        cursor: pointer;
        max-height: 70%;
        overflow-y: auto;
        overflow-x: hidden;
    }

    .post-toc .post-toc-title {
        width: 100%;
        margin: 0 auto;
        font-size: 20px;
        font-weight: 400;
        text-transform: uppercase;
        text-align: center;
    }

    .post-toc .post-toc-content {
        font-size: 15px;
    }

    .post-toc .post-toc-content>nav>ul {
        margin: 10px 0;
    }

    .post-toc .post-toc-content ul {
        padding-left: 20px;
        list-style: square;
        margin: 0.5em;
        line-height: 1.8em;
    }

    .post-toc .post-toc-content ul ul {
        padding-left: 15px;
        display: none;
    }

    @media print,
    screen and (max-width:1057px) {
        .post-toc {
            display: none;
        }
    }
</style>
<div class="post-toc" style="position: absolute; top: 188px;">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#one大模型选型">ONE.大模型选型</a></li>
    <li><a href="#大模型的概念和重要性">大模型的概念和重要性</a></li>
    <li><a href="#常见大模型介绍和对比">常见大模型介绍和对比</a></li>
    <li><a href="#最终模型选型和理由">最终模型选型和理由</a></li>
    <li><a href="#two硬件选型">TWO.硬件选型</a></li>
    <li><a href="#硬件需求分析">硬件需求分析</a></li>
    <li><a href="#可选硬件方案对比">可选硬件方案对比</a></li>
    <li><a href="#最终选型和理由">最终选型和理由</a></li>
    <li><a href="#threellm应用框架选型">THREE.LLM应用框架选型</a></li>
    <li><a href="#llm应用框架的作用和重要性">LLM应用框架的作用和重要性</a></li>
    <li><a href="#常见llm应用框架介绍和对比">常见LLM应用框架介绍和对比</a></li>
    <li><a href="#最终框架选型和理由">最终框架选型和理由</a></li>
    <li><a href="#four如何对接到llm">FOUR.如何对接到LLM</a></li>
    <li><a href="#对接llm的一般步骤">对接LLM的一般步骤</a></li>
    <li><a href="#常见问题和解决方案">常见问题和解决方案</a></li>
    <li><a href="#five系统测试与优化">FIVE.系统测试与优化</a></li>
    <li><a href="#测试方法和标准">测试方法和标准</a></li>
    <li><a href="#测试结果与分析">测试结果与分析</a></li>
    <li><a href="#优化方向和步骤">优化方向和步骤</a></li>
    <li><a href="#结论">#结论</a></li>
    <li><a href="#研究成果总结">研究成果总结：</a></li>
    <li><a href="#研究的局限性">研究的局限性：</a></li>
    <li><a href="#未来研究方向">未来研究方向：</a></li>
  </ul>
</nav>
    </div>
</div>
<script type="text/javascript">
    $(document).ready(function () {
        var postToc = $(".post-toc");
        if (postToc.length) {
            var leftPos = $("#main").offset().left;
            if(leftPos<220){
                postToc.css({"width":leftPos-10,"margin-left":(0-leftPos)})
            }

            var t = postToc.offset().top - 20,
                a = {
                    start: {
                        position: "absolute",
                        top: t
                    },
                    process: {
                        position: "fixed",
                        top: 20
                    },
                };
            $(window).scroll(function () {
                var e = $(window).scrollTop();
                e < t ? postToc.css(a.start) : postToc.css(a.process)
            })
        }
    })
</script>
    <article class="post">
        <header>
            <h1 class="post-title">技术分享 - 基于大模型（LLM）的智能化自助分析系统搭建探索 -- 知识铺</h1>
        </header>
        <date class="post-meta meta-date">
            2024年3月18日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            <p><strong>研究背景：</strong></p>
<p>随着人工智能的快速发展，大型语言模型（LLM）已经在各种场景中展现了惊人的应用价值，从自然语言处理到复杂的数据分析，LLM似乎正在不断改变我们获取和处理信息的方式。</p>
<p>然而，如何有效地利用这些模型，以及如何根据特定的应用需求进行选型和配置，仍然是许多研究者和开发者面临的挑战。</p>
<p>基于上述背景，我们经过内部的探索，决定和大家分享一下如何从零开始，基于大语言模型，一步步搭建一个基础的数据查询系统，实现自然语言交互下的企业指标数据和报表的可视化展示。</p>
<p><strong>研究目标：</strong></p>
<p>我们的目标是为读者提供一个基于大型语言模型的自助分析系统的搭建过程。我们将从硬件选型开始，探讨如何选择适合的硬件设备，然后介绍大模型的选型，以及如何选择合适的LLM应用框架。最后，我们将详细讨论如何将大语言模型和数据库等部分对接，以构建一个完整的系统。</p>
<p>在这个过程中，我们将尽可能地详细解释每一步的理由和考虑，以帮助读者理解并应用到自己的项目中。通过这篇文章，我们希望能够为读者提供一个清晰、易于理解的指南，帮助他们更好地利用大型语言模型的强大功能。</p>
<h2 id="one大模型选型">ONE.大模型选型</h2>
<h2 id="大模型的概念和重要性">大模型的概念和重要性</h2>
<p>大型语言模型（LLM），如GPT系列、BERT、和T5，是一种基于深度学习的自然语言处理技术。这些模型通过在大规模数据集上预训练，学会了理解和生成人类语言的复杂模式。预训练之后，它们能够在多种语言任务上进行微调，比如文本分类、情感分析、问答系统、文本摘要和语言翻译等。</p>
<p>这些模型之所以被称为“大”，不仅是因为它们在大量的文本数据上进行训练，而且它们的模型结构通常包含数十亿甚至数万亿个参数。这种规模的模型能够捕捉到语言的细微差别和复杂关系，使其在处理各种语言相关任务时表现出色。</p>
<p>LLM在现代人工智能领域扮演着至关重要的角色。以下几点概述了它们的重要性：</p>
<p>**1. 理解和生成能力：**LLM的核心优势在于其出色的语言理解和生成能力。这使得它们可以被应用于聊天机器人、内容创作、法律文件分析等多种场景。</p>
<p>**2. 跨领域适用性：**与专门为特定任务设计的模型不同，LLM具有很强的泛化能力，能够在多个领域和任务中实现无缝迁移和应用。</p>
<p>**3. 减少任务特定训练：**由于LLM已经在大量的语言数据上进行了预训练，因此即使是对于特定任务的微调也需要的训练数据相对较少。</p>
<p>**4. 知识整合和推理：**LLM能够整合其在训练过程中学到的广泛知识，并在适当的情况下进行推理和应用。</p>
<p>**5. 技术创新的推动者：**LLM的开发和应用推动了算法的创新，促进了更高效的模型架构和训练技术的出现。</p>
<p>**6. 经济和社会影响：**LLM的应用正在改变许多行业的运作方式，从而对经济和社会产生深远影响。</p>
<p>因此，了解大型语言模型的工作原理、潜力以及如何有效地部署和利用它们，对于希望在人工智能领域取得突破的研究者和实践者来说，是至关重要的。</p>
<h2 id="常见大模型介绍和对比">常见大模型介绍和对比</h2>
<p>这部分我们主要参考 SuperCLUE 排行榜，选定了几个开源可商用的大模型作为候选，按参数量划分：</p>
<p><strong>6B/7B：</strong></p>
<p>轻量级，适用于资源有限的环境。在处理一般性任务时可能表现得较好，尤其是当计算资源有限时。较小的模型适用于简单的数据分析任务，特别是在数据规模较小或特征较少的情况下。</p>
<p>
        <img class="mx-auto" alt="" src="https://p3-sign.toutiaoimg.com/tos-cn-i-axegupay5k/33f1cfa37e084c7b9bb8ac83e6e44d0b~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1711370384&amp;x-signature=%2FRbkLovc4eV9ytVr%2FBvPTKS2Hf8%3D" />   
    </p>
<p><strong>12-14B：</strong></p>
<p>具有更强大的表示能力，能够更好地捕捉语言的复杂性。适用于更大规模的任务，如自然语言理解、生成和其他复杂的NLP任务，更好地捕捉数据中的复杂模式和关系。</p>
<p>
        <img class="mx-auto" alt="" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/fd20d4e7ee59407d83921b78be1e5428~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1711370384&amp;x-signature=H11Pvz7chwgaXIGChPui2GynpTs%3D" />   
    </p>
<p><strong>20B及以上：</strong></p>
<p>适用于大规模NLP任务、生成性任务和其他需要深度理解语言结构的应用。</p>
<p>
        <img class="mx-auto" alt="" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/539f9badfca3415f98c4a1b53162dcd8~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1711370384&amp;x-signature=ye6sZMzsMYqJZed2bHp2nspOxNc%3D" />   
    </p>
<p>综上所述：</p>
<p>在参数量为6B时，ChatGLM3-6B (base)模型综合表现较好，并且可以商用，其在文档摘要和财报分析等应用场景中表现较好。</p>
<p>在参数大小为12-14B时，建议可以使用Qwen14B。</p>
<p>若用户要求较高准确率的产品，可以使用Yi-34B。</p>
<h2 id="最终模型选型和理由">最终模型选型和理由</h2>
<p>基于大模型的调研情况，我们决定暂时使用网上的 GPT 3.5 API 进行研发，等软件的功能通过验证完成，准备发布到生产环境时，再考虑切换到开源的大模型上。</p>
<h2 id="two硬件选型">TWO.硬件选型</h2>
<h2 id="硬件需求分析">硬件需求分析</h2>
<p>经过查阅资料，我们了解到，生产环境一般运行的模型是 INT8 量化的版本。并且考虑到还要存储一些中间结果，或者被其他应用消耗部分显存，所以基本上 8Gb 的显卡，只能运行小于 8B 的大模型。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2024/f2c8db3b843a4858b3c13151076bfcdc~noop.image" />   
    </p>
<p>如果需要考虑训练模型，训练一个大型模型（如一个有1750亿个参数的语言模型）涉及到巨大的计算和存储需求。这里假设用混合精度技术，根据上述图片提到的几个内存成本分项，可以这样理解：</p>
<p><strong>1.参数 (350 GB):</strong> 参数是模型中可学习的部分，例如权重(weights)。这里的1750亿个参数需要存储它们的数值。如果每个参数用2字节来存储（比如使用16位浮点数），那么总共需要的存储空间大约是350 GB。</p>
<p><strong>2.梯度 (350 GB):</strong> 在模型训练过程中，需要计算每个参数的梯度，以便进行反向传播。梯度的大小和参数的大小是一样的，因此也需要350 GB的存储空间。</p>
<p><strong>3.主参数 (700 GB):</strong> 为了提高数值精度，通常会有一份参数的副本以更高的精度存储，例如使用32位浮点数。这就是所谓的“主参数”，它们需要的存储空间是原始参数的两倍，即700 GB。</p>
<p><strong>4.Adam Optimizer状态 (1400 GB):</strong> Adam优化器是一个流行的优化算法，它为每个参数维护两个额外的向量：一个用于存储过去梯度的指数衰减平均值（第一矩估计），另一个用于存储过去梯度平方的指数衰减平均值（第二矩估计）。每个向量的大小都和参数本身一样，且通常使用32位浮点数存储，因此需要的存储空间是参数空间的两倍，即1400 GB。</p>
<p>当你把上述所有的存储需求加起来，你会得到总共需要2.8 TB的内存来训练这个模型。相当于推理所需显存大小的 16 倍。需要注意的是，上面提到的内存成本是针对单个数据副本的情况。在实际操作中，由于需要并行处理和数据冗余等因素，实际内存需求可能会更高。此外，这还没有考虑到其他可能的内存需求，如激活值、临时变量等。</p>
<p>由于训练模型的成本较高，所以如果考虑微调，一般情况下都是选择使用 LoRA 等高效微调技术进行微调。</p>
<h2 id="可选硬件方案对比">可选硬件方案对比</h2>
<p>大型语言模型（LLM），如GPT系列、BERT、和T5，是一种基于深度学习的自然语言处理技术。这些模型通过在大规模数据集上预训练，学会了理解和生成人类语言的复杂模式。预训练之后，它们能够在多种语言任务上进行微</p>
<p>基于上面提到的开源模型，我们调研了几个方案：</p>
<p><strong>方案一：（6.5万左右）</strong></p>
<p>采购：4块RTX4090</p>
<p>可部署模型对象：Yi 34B-chat（1911元/B）， Qwen-72B（902元/B）（微调模型推荐为62GB，3块4080。base模型推荐为：48.9G，两块4090）</p>
<p>优点：以Yi 34B-chat为代表的模型性能较强，介于ChatGpt4和ChatGpt3.5之间。</p>
<p>缺点：本地部署的成本高。</p>
<p><strong>方案二：（1万左右）</strong></p>
<p>采购：一块RTX4080 （16G）/ 两块RTX3080或一块3090</p>
<p>可部署模型对象：ChatGLM3-6B（1666元/B）（13G以上），Qwen-14B（714 元/B）（base模型，13G以上），Baichuan2-7B（约1666元/B）（15.3G）</p>
<p>优点：该类模型能处理好一般性的推理需求，部署成本适中。</p>
<p>缺点：可能无法处理复杂维度的问题，如设计图像的处理和生成。对部分中高端模型，微调能力有限。</p>
<p><strong>方案三：（1万5-2万）</strong></p>
<p>采购：两块RTX4080（16G）/ 一块3080+一块3090</p>
<p>可部署模型对象：Baichuan2-13B-Chat（1380元/B）（27.5G以上），Qwen-14B（1285 元/B）（微调模型，18.7G以上，两块RTX4070）</p>
<p>优点：模型性能介于方案一二中的模型性能之间，总显存大小在32G左右，适配大部分中低端模型。可对大部分模型进行微调。</p>
<p><strong>附上采购价格参考（京东）：</strong></p>
<p>
        <img class="mx-auto" alt="" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/8110a70889654cd38ae899e2fd2d47dc~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1711370384&amp;x-signature=nz3x48JG0vAEO6US49jSMAK0l04%3D" />   
    </p>
<h2 id="最终选型和理由">最终选型和理由</h2>
<p>如果选择 2.3 提到的模型，最低配置为方案三，理想配置为方案一甚至更高。</p>
<h2 id="threellm应用框架选型">THREE.LLM应用框架选型</h2>
<h2 id="llm应用框架的作用和重要性">LLM应用框架的作用和重要性</h2>
<p>在大型语言模型（LLM）的世界中，应用框架是指那些支持模型部署、集成和交互的工具和库。这些框架的主要作用可以概括为以下几点：</p>
<p>**1. 简化部署：**框架提供了一系列工具和API，使得在不同环境中部署LLM变得更加简单和高效。</p>
<p>**2. 统一接口：**通过标准化的接口，开发者可以更容易地与模型进行交云，并集成到现有的系统中。</p>
<p>**3. 性能优化：**框架通常包含了优化工具，能够帮助提升模型在特定硬件上的执行效率。</p>
<p>**4. 扩展性和可维护性：**良好设计的框架能够支持模型的扩展和升级，同时也便于维护和更新。</p>
<p>**5. 安全性和合规性：**框架可以提供安全功能，帮助保护模型数据的安全性，并确保使用符合行业标准和法规要求。</p>
<p>LLM应用框架在实现大型语言模型的商业和研究应用中扮演着至关重要的角色。以下几点强调了它们的重要性：</p>
<p>**1. 加速研发：**框架提供的抽象层可以减少开发者在底层编程上的工作量，从而加速从概念到产品的开发周期。</p>
<p>**2. 降低技术门槛：**框架使得即便是非专业的开发者也能够利用LLM的强大功能，拓宽了人工智能技术的应用范围。</p>
<p>**3. 促进创新：**标准化的框架可以鼓励开发者专注于创新而不是重复基础工作，从而推动整个领域的发展。</p>
<p>**4. 支持多样化应用：**框架的灵活性和扩展性意味着LLM能够被应用于从医疗健康到金融服务等广泛的行业。</p>
<p>**5. 确保可靠性和稳定性：**框架的支持和维护确保了基于LLM的系统可以在长期运行中保持高性能和稳定性。</p>
<p>因此，选择正确的LLM应用框架是构建高效、可靠且可扩展的智能化自助分析系统的关键步骤。它不仅影响系统的开发和维护成本，还直接关系到最终用户体验的质量。</p>
<h2 id="常见llm应用框架介绍和对比">常见LLM应用框架介绍和对比</h2>
<p>常见的 LLM 应用框架包括了以下几种类型：</p>
<p>LangChain、Langchain-Chatchat、Langflow、Flowise、Dify、Bisheng、FastGPT、AutoGenStudio，这里我给他们做了个对比：</p>
<p>
        <img class="mx-auto" alt="" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/4fa8474d248c40f6badd577b4c24834f~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1711370384&amp;x-signature=doRrhcFgQmuRObxox6%2BmNVK7pwY%3D" />   
    </p>
<p>这些框架，其实底层都是基于 LangChain 做二次开发或者简化封装，AutoGenStudio有一个突破性的工作是原生支持了“工作流”，即允许多个Agent自行交流以完成任务，但是可能对大模型的要求较高。Langflow和Flowise基本上就是LangChain的可拖拽的版本，实际上用起来需要熟悉LangChain。Dify看起来不错，但目前缺少编排功能。FastGPT则看起来比较轻量，而且不需要熟悉 LangChain。</p>
<h2 id="最终框架选型和理由">最终框架选型和理由</h2>
<p>最终看来 FastGPT 可以一试，如果后续需要复杂的多 Agent 协同，可以考虑接入AutoGenStudio。</p>
<h2 id="four如何对接到llm">FOUR.如何对接到LLM</h2>
<h2 id="对接llm的一般步骤">对接LLM的一般步骤</h2>
<p>以 FastGPT为例，对接 GPT 的一般步骤：</p>
<p>1、部署LLM，取得One API调用接口，相关文档</p>
<p>2、通过 docker image部署 FastGPT，其中包含了 PG 和 MongoDB，相关文档</p>
<p>3、在 FastGPT 界面中创建应用，切换到高级编排模式，然后在 AI 大模型聊天模块内，即可找到切换 LLM 的选项</p>
<p>4、业务平台提供给 FastGPT 调用的接口，需要另外开发，这里不再赘述。</p>
<p>5、应用支持创建一个外部使用的免登录窗口，可以将与 AI 的聊天窗口作为 iframe 嵌入业务平台。</p>
<h2 id="常见问题和解决方案">常见问题和解决方案</h2>
<p>1、查询数据接口的免登录，可以预先在业务平台生成 JWT令牌，然后作为参数嵌入到接口的调用参数内。</p>
<p>2.、图表展示，可直接使用 QuickChart，它是一个开源的图表展示服务，省去了自己开发类似服务的工作量。</p>
<h2 id="five系统测试与优化">FIVE.系统测试与优化</h2>
<h2 id="测试方法和标准">测试方法和标准</h2>
<p>**1、功能性：**主要通过询问AI，看它能否提供正确的回答或图表来测试</p>
<p>**2、性能：**判断 AI 能否在适当的时间内给予用户答复。</p>
<p>**3、安全性：**需要注意，生产环境不应使用外部接口，只能使用内部部署的大模型。</p>
<h2 id="测试结果与分析">测试结果与分析</h2>
<p>在本研究中，我们对基于大模型的自助分析系统进行了一系列的测试，旨在评估系统的性能、准确性和用户体验。</p>
<p>测试结果表明，系统在处理简单查询时表现出较高的准确率和响应速度，用户反馈表明系统界面直观且易于操作。然而，在面对更复杂的数据集和查询时，系统的性能有所下降，错误率相对较高。</p>
<p>分析原因可能是我们对 FastGPT 的知识库的准备不够深入，以及Agent的逻辑编排中存在的逻辑漏洞。此外，一些用户反馈在交互过程中遇到了理解上的困难，提示我们需要进一步优化用户指导和帮助文档。</p>
<p>
        <img class="mx-auto" alt="" src="https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/070b51a8ba604fc69b93a60e3edd094a~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1711370384&amp;x-signature=Sex8MVpt8luq8zD8YKRvBSQDaMc%3D" />   
    </p>
<p>图：系统效果展现</p>
<h2 id="优化方向和步骤">优化方向和步骤</h2>
<p>针对测试中发现的问题，我们计划采取以下优化方向和步骤：</p>
<p>**1、自动更新知识库：**为了提高大模型在业务领域的准确性，我们将更好地对接业务系统与知识库，自动将业务指标及其描述，及时同步到知识库，以增强模型对专业术语和上下文的理解。</p>
<p>**2、查询转换逻辑改进：**我们将重新审视和优化Agent的Prompt和编排逻辑，确保即使是复杂的查询也能被正确理解并转换。</p>
<h2 id="结论">#结论</h2>
<h2 id="研究成果总结">研究成果总结：</h2>
<p>本研究的初步尝试展示了基于大模型技术构建的智能化自助分析系统的可行性。我们编排了一个应用，使得业务人员能够通过自然语言与数据查询系统进行交互，简化了数据访问和分析的过程。虽然目前的成果是初步的，但已经能够处理一系列基础的数据查询需求，并将结果以图表的形式展现，这对于非技术人员来说，是一个明显的便利。</p>
<h2 id="研究的局限性">研究的局限性：</h2>
<p>目前的研究成果尚处于早期阶段，存在一些局限性。例如，对硬件资源的依赖性较高，可能会增加实施成本。当前所使用的大模型虽然功能强大，但在处理一些特定领域或复杂查询时仍可能存在准确性挑战。此外，系统的稳定性、扩展性以及用户界面的友好性都需要在后续的研究中进一步改进和测试。对于隐私和安全性问题，尽管已经有所考虑，但这些方面的解决方案仍然需要根据未来的技术发展进行调整和完善。</p>
<h2 id="未来研究方向">未来研究方向：</h2>
<p>鉴于当前研究的局限性，未来的工作将集中在以下几个方面：首先，研究更为经济且高效的硬件配置方案，以减轻成本压力。其次，持续优化模型的选择和调整，提升系统处理特定查询的能力。进一步开发和测试系统的稳定性和用户体验，使之更加适应实际业务需求。同时，继续探索数据隐私和安全性的最佳实践，确保系统的可靠性。最后，考虑将研究成果逐步应用于更多的业务场景中，以验证和扩展系统的实用性。通过这些努力，我们期望能够不断完善系统，最终实现一个成熟、高效、安全的智能化自助分析平台。</p>

        </div>

        <form style="border:1px solid #ccc;padding:3px;text-align:center;" action="https://tinyletter.com/sblig" method="post" target="popupwindow" onsubmit="window.open('https://tinyletter.com/sblig', 'popupwindow', 'scrollbars=yes,width=800,height=600');return true"><p><label for="tlemail">订阅每周最新ChatGPT技术和动向</label></p><p><input type="text" style="width:140px" name="email" id="tlemail" /></p><input type="hidden" value="1" name="embed"/><input type="submit" value="邮箱订阅" /> </form>

<div class="post-archive">
    <ul class="post-copyright">
        <li><strong>原文作者：</strong><a rel="author" href="https://gpt.zshipu.com/">知识铺</a></li>
        <li style="word-break:break-all"><strong>原文链接：</strong><a href="https://gpt.zshipu.com/post/202403/LLM/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8BLLM%E7%9A%84%E6%99%BA%E8%83%BD%E5%8C%96%E8%87%AA%E5%8A%A9%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA%E6%8E%A2%E7%B4%A2-%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1/">https://gpt.zshipu.com/post/202403/LLM/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E5%9F%BA%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8BLLM%E7%9A%84%E6%99%BA%E8%83%BD%E5%8C%96%E8%87%AA%E5%8A%A9%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA%E6%8E%A2%E7%B4%A2-%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1/</a></li>
        <li><strong>版权声明：</strong>本作品采用<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>进行许可，非商业转载请注明出处（作者，原文链接），商业转载请联系作者获得授权。</li>
        <li><strong>免责声明：</strong>本页面内容均来源于站内编辑发布，部分信息来源互联网，并不意味着本站赞同其观点或者证实其内容的真实性，如涉及版权等问题，请立即联系客服进行更改或删除，保证您的合法权益。转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。也可以邮件至 sblig@126.com</li>
    </ul>
</div>
<br/>



        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/post/202403/LLM/%E5%BE%AE%E8%BD%AF6%E9%A1%B5%E8%AE%BA%E6%96%87%E7%88%86%E7%81%AB%E4%B8%89%E8%BF%9B%E5%88%B6LLM%E7%9C%9F%E9%A6%99-%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1/">微软6页论文爆火：三进制LLM，真香！ -- 知识铺</a></li>
        
        <li><a href="/post/202403/LLM/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-LLM-%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1/">大型语言模型 (LLM) -- 知识铺</a></li>
        
        <li><a href="/post/202403/LLM/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%A4%A7%E5%BC%80%E6%BA%90LLM%E5%8F%82%E6%95%B0%E9%AB%98%E8%BE%BE3140%E4%BA%BF%E9%A9%AC%E6%96%AF%E5%85%8B%E5%A6%82%E7%BA%A6%E5%BC%80%E6%BA%90Grok10%E5%B0%8F%E6%97%B6%E7%8B%82%E6%8F%BD10000%E9%A2%97Star-36%E6%B0%AA/">史上最大开源LLM，参数高达3140亿，马斯克如约开源Grok，10小时狂揽10000颗Star-36氪 -- 知识铺</a></li>
        
        <li><a href="/post/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%88%9D%E5%88%9B%E5%85%AC%E5%8F%B8%E5%A6%82%E4%BD%95%E7%AD%B9%E9%9B%86%E6%95%B0%E7%99%BE%E4%B8%87%E7%BE%8E%E5%85%83/">人工智能初创公司如何筹集数百万美元</a></li>
        
        <li><a href="/post/202311/001-%E5%80%BC%E5%BE%97%E4%BD%A0%E8%8A%B1%E6%97%B6%E9%97%B4%E9%98%85%E8%AF%BB%E7%9A%84-5-%E4%B8%AA-freeCodeCamp-%E8%B5%84%E6%BA%90/">001 值得你花时间阅读的 5 个 freeCodeCamp 资源</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='/tags/LLM'>LLM</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "zshipu/gpt"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2024 <a href="https://gpt.zshipu.com/">GPT资讯  --  知识铺 By 知识铺</a>
        
        | <a rel="nofollow" target="_blank" href="https://beian.miit.gov.cn/">浙 ICP 备19032823号-1</a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://gpt.zshipu.com/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://gpt.zshipu.com/">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/%E4%B8%BA%E6%82%A8%E7%9A%84-AI-%E9%A1%B9%E7%9B%AE%E9%9B%87%E7%94%A8-GPT-Prompt-%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E6%8C%87%E5%8D%97---A-Guide-on-Hiring-GPT-Prompt-Engineers-for-Your-AI-Project/" title="为您的 AI 项目雇用 GPT Prompt 工程师的指南 --- A Guide on Hiring GPT Prompt Engineers for Your AI Project -- 知识铺">为您的 AI 项目雇用 GPT Prompt 工程师的指南 --- A Guide on Hiring GPT Prompt Engineers for Your AI Project -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/2024-%E5%B9%B4-9-%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8F%90%E7%A4%BA%E7%94%9F%E6%88%90%E5%99%A8ChatGPTMidjourney-%E7%AD%89-The-Tech-Edvocate---9-Best-AI-Prompt-Generators-2024-ChatGPT-Midjourney-More-The-Tech-Edvocate/" title="2024 年 9 个最佳人工智能提示生成器（ChatGPT、Midjourney 等） - The Tech Edvocate --- 9 Best AI Prompt Generators 2024 (ChatGPT, Midjourney &amp; More) - The Tech Edvocate -- 知识铺">2024 年 9 个最佳人工智能提示生成器（ChatGPT、Midjourney 等） - The Tech Edvocate --- 9 Best AI Prompt Generators 2024 (ChatGPT, Midjourney &amp; More) - The Tech Edvocate -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82-Prompt-%E7%BC%96%E7%A8%8Bv2/" title="一文搞懂 Prompt 编程v2 -- 知识铺">一文搞懂 Prompt 编程v2 -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82-Prompt-%E7%BC%96%E7%A8%8B/" title="一文搞懂 Prompt 编程 -- 知识铺">一文搞懂 Prompt 编程 -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/%E4%BB%80%E4%B9%88%E6%98%AFPrompt%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5-luch%E7%9A%84%E5%8D%9A%E5%AE%A2/" title="什么是Prompt？——深度学习中的重要概念 - luch的博客 -- 知识铺">什么是Prompt？——深度学习中的重要概念 - luch的博客 -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/Effective-Prompt-%E7%BC%96%E5%86%99%E9%AB%98%E8%B4%A8%E9%87%8FPrompt%E7%9A%8414%E4%B8%AA%E6%9C%89%E6%95%88%E6%96%B9%E6%B3%95-%E7%9F%A5%E4%B9%8E/" title="Effective Prompt 编写高质量Prompt的14个有效方法 - 知乎 -- 知识铺">Effective Prompt 编写高质量Prompt的14个有效方法 - 知乎 -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/6%E4%B8%AAAI%E9%AB%98%E6%89%8B%E9%83%BD%E5%9C%A8%E7%94%A8%E7%9A%84%E6%8F%90%E7%A4%BA%E8%AF%8Dprompt%E7%BD%91%E7%AB%99%E5%BB%BA%E8%AE%AE%E6%94%B6%E8%97%8F-%E7%9F%A5%E4%B9%8E/" title="6个AI高手都在用的提示词prompt网站，建议收藏！ - 知乎 -- 知识铺">6个AI高手都在用的提示词prompt网站，建议收藏！ - 知乎 -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/Prompt%E8%90%A5%E9%94%80%E7%9A%84%E9%9B%B7%E7%A5%9E%E4%B9%8B%E9%94%A4_%E8%85%BE%E8%AE%AF%E6%96%B0%E9%97%BB/" title="Prompt：营销的雷神之锤_腾讯新闻 -- 知识铺">Prompt：营销的雷神之锤_腾讯新闻 -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/OpenAI%E7%9A%84%E5%AE%98%E6%96%B9Prompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97%E8%AF%A6%E8%A7%A3-%E7%9C%8B%E8%BF%99%E4%B8%80%E7%AF%87%E7%9C%9F%E7%9A%84%E5%B0%B1%E5%A4%9F%E4%BA%86_%E8%85%BE%E8%AE%AF%E6%96%B0%E9%97%BB/" title="OpenAI的官方Prompt工程指南详解 - 看这一篇真的就够了_腾讯新闻 -- 知识铺">OpenAI的官方Prompt工程指南详解 - 看这一篇真的就够了_腾讯新闻 -- 知识铺</a>
    </li>
    
    <li>
        <a href="https://gpt.zshipu.com/post/202403/prompt/%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%E8%AE%A9%E4%BD%A0%E6%88%90%E4%B8%BAprompt%E4%B8%93%E5%AE%B6-%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1/" title="一篇文章让你成为prompt专家 -- 知识铺">一篇文章让你成为prompt专家 -- 知识铺</a>
    </li>
    
</ul>
    </section>

    
<section class="widget">
    <h3 class="widget-title" style="color:red">福利派送</h3>
    <ul class="widget-list">
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="【2019双12】ALL IN CLoud 低至1折" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1_rYHo7P2gK0jSZPxXXacQpXa-690-388.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="助力产业智慧升级，云服务器首年88元起，更有千元代金券礼包免费领！" target="_blank" style="color:red">
                
                    <img src="https://upload-dianshi-1255598498.file.myqcloud.com/345-7c71532bd4935fbdd9a67c1a71e577b1767b805c.200%E7%89%88%E6%9C%ACB.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="【渠道专享低折扣】11月特惠 限时2折" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1hblJl7Y2gK0jSZFgXXc5OFXa-750-400.jpg">
                
            </a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title"><a href='/categories/'>分类</a></h3>
<ul class="widget-list">
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href='/tags/'>标签</a></h3>
<div class="tagcloud">
    
    <a href="https://gpt.zshipu.com/tags/AI/">AI</a>
    
    <a href="https://gpt.zshipu.com/tags/GPT/">GPT</a>
    
    <a href="https://gpt.zshipu.com/tags/LLM/">LLM</a>
    
    <a href="https://gpt.zshipu.com/tags/Midjourney/">Midjourney</a>
    
    <a href="https://gpt.zshipu.com/tags/prompt/">prompt</a>
    
    <a href="https://gpt.zshipu.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="https://geek.zshipu.com//" title="知识铺的博客">知识铺的博客</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://gpt.zshipu.com/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>
<script
  src="https://js.sentry-cdn.com/5c69c7b20860be9ded39ad4778ddc21e.min.js"
  crossorigin="anonymous"
></script>

</html>